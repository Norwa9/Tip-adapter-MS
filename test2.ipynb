{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8375, 0.3225],\n",
      "         [0.5488, 0.2301]],\n",
      "\n",
      "        [[0.4722, 0.1360],\n",
      "         [0.4242, 0.8377]],\n",
      "\n",
      "        [[0.2532, 0.2531],\n",
      "         [0.4185, 0.2456]],\n",
      "\n",
      "        [[0.8839, 0.7750],\n",
      "         [0.8140, 0.5263]]]) tensor([[[0.9472, 0.9957]],\n",
      "\n",
      "        [[0.1605, 0.6259]],\n",
      "\n",
      "        [[0.4325, 0.5864]],\n",
      "\n",
      "        [[0.1911, 0.5343]]]) tensor([[[1.7847, 1.3182],\n",
      "         [1.4960, 1.2258]],\n",
      "\n",
      "        [[0.6327, 0.7619],\n",
      "         [0.5846, 1.4636]],\n",
      "\n",
      "        [[0.6857, 0.8395],\n",
      "         [0.8510, 0.8320]],\n",
      "\n",
      "        [[1.0750, 1.3093],\n",
      "         [1.0051, 1.0607]]])\n",
      "torch.Size([4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "batch = 4\n",
    "seq_len = 2\n",
    "dim = 2\n",
    "a=torch.rand(batch,seq_len,dim)\n",
    "b=torch.rand(batch,1,dim)\n",
    "# b = b.repeat(1,seq_len,1)\n",
    "# res = torch.concat([a,b],dim=-1)\n",
    "res = a+b\n",
    "print(a,b,res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.rand(4,5)\n",
    "target = torch.randint(0,5,(4,1))\n",
    "pred = output.topk(5, 1, True, True)[1].t()\n",
    "expand_target = target.view(1, -1).expand_as(pred)\n",
    "correct = pred.eq(expand_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3])\n"
     ]
    }
   ],
   "source": [
    "output = torch.rand(4,5)\n",
    "top1 = output.topk(1)[1]\n",
    "print(top1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144, 541, 783, 774, 165, 348, 606, 180, 72, 59]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "res = random.sample(range(1000),10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sapmle_topk1_prototypes(logits:torch.Tensor, targets:torch.Tensor, topK:int):\n",
    "    cls_num = logits.shape[1]\n",
    "    batch = logits.shape[0]\n",
    "    \n",
    "\n",
    "    origin_target = []\n",
    "    new_target = torch.zeros(batch,1).view(-1)\n",
    "    for i, target in enumerate(targets):\n",
    "        random_targets = random.sample(range(cls_num),topK+1)\n",
    "        if target in random_targets:\n",
    "            new_target[i] = random_targets.index(target)\n",
    "        else:\n",
    "            random_targets[0] = target.numpy()\n",
    "        origin_target =  np.append(origin_target, random_targets)\n",
    "    \n",
    "    origin_target = origin_target.reshape(batch,-1)\n",
    "    new_target = new_target.cuda()\n",
    "\n",
    "    return new_target, origin_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 6, 3, 2, 8],\n",
      "        [5, 7, 4, 1, 8],\n",
      "        [9, 5, 3, 7, 6],\n",
      "        [5, 6, 9, 4, 1]])\n",
      "tensor([8, 6, 2, 5])\n",
      "tensor([1., 0., 0., 2.], device='cuda:0')\n",
      "[[3. 8. 6. 4. 1. 9.]\n",
      " [6. 3. 2. 4. 7. 5.]\n",
      " [2. 4. 9. 5. 8. 0.]\n",
      " [9. 2. 5. 4. 1. 8.]]\n"
     ]
    }
   ],
   "source": [
    "cls_num = 10\n",
    "batch = 4\n",
    "logits = torch.rand(batch,cls_num)\n",
    "target = torch.randint(0,cls_num,(batch,1)).view(-1)\n",
    "new_target, origin_target = sapmle_topk1_prototypes(logits,target,5)\n",
    "\n",
    "print(logits.topk(5)[1])\n",
    "print(target)\n",
    "print(new_target)\n",
    "print(origin_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2])\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 4, 0, 3]\n",
      "[7, 9, 6, 8, 1]\n",
      "[1, 7, 0, 6, 3]\n",
      "[6, 0, 7, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        res = random.sample(range(10),5)\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# att rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9217, 0.7232]])\n",
      "tensor([[0.0415, 0.9692]])\n"
     ]
    }
   ],
   "source": [
    "batch = 1\n",
    "k = 2\n",
    "y = abs(torch.rand(batch, k))\n",
    "res = abs(torch.rand(batch, k))\n",
    "print(y)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_rank(y):\n",
    "    exp_y = torch.exp(y)\n",
    "    # print(f'exp_y:{exp_y}')\n",
    "    sum = torch.sum(exp_y,dim=-1).unsqueeze(-1)\n",
    "    # print(f'sum:{sum}')\n",
    "    y = exp_y / sum\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.6860)\n"
     ]
    }
   ],
   "source": [
    "y = att_rank(y)\n",
    "res = att_rank(res)\n",
    "loss1 = y*torch.log(res)\n",
    "loss2 = (1-y)*torch.log(1-res)\n",
    "Loss = loss1+loss2\n",
    "print(Loss.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1,  1])\n",
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.tensor([-1,1])\n",
    "print(x)\n",
    "print(F.relu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:tensor([[0.7322, 0.7518, 0.5606, 0.7673, 0.2505, 0.3466, 0.2546, 0.4729, 0.4775,\n",
      "         0.0329],\n",
      "        [0.0604, 0.7217, 0.2045, 0.5660, 0.2487, 0.7841, 0.5745, 0.1031, 0.1405,\n",
      "         0.0032],\n",
      "        [0.7634, 0.6003, 0.2764, 0.4705, 0.7311, 0.0862, 0.1134, 0.0888, 0.1834,\n",
      "         0.6933],\n",
      "        [0.7720, 0.9737, 0.1762, 0.4136, 0.4142, 0.2692, 0.9401, 0.9956, 0.7636,\n",
      "         0.0167]])\n",
      "indices:tensor([[6, 9, 6, 4, 9],\n",
      "        [3, 9, 2, 1, 3],\n",
      "        [0, 6, 4, 8, 5],\n",
      "        [3, 9, 0, 4, 6]])\n",
      "tensor([[0.2546, 0.0329, 0.2546, 0.2505, 0.0329],\n",
      "        [0.5660, 0.0032, 0.2045, 0.7217, 0.5660],\n",
      "        [0.7634, 0.1134, 0.7311, 0.1834, 0.0862],\n",
      "        [0.4136, 0.0167, 0.7720, 0.4142, 0.9401]])\n"
     ]
    }
   ],
   "source": [
    "cls_num = 10\n",
    "batch = 4\n",
    "k = 5\n",
    "logits = torch.rand(batch,cls_num)\n",
    "print(f'logits:{logits}')\n",
    "indices = torch.randint(0,cls_num,(batch,k))\n",
    "print(f'indices:{indices}')\n",
    "logits2 = torch.stack([logits[i][indices[i]] for i in range(batch)])\n",
    "print(logits2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, cls_num):\n",
    "    one_hot_target = torch.zeros((y.shape[0], cls_num))\n",
    "    for i,target in enumerate(y):\n",
    "            one_hot_target[i][target] = 1\n",
    "    return one_hot_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "res = one_hot(a,100)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "952a9237107f23337e2cf64b27dea29cd0600c26eb7b44c973b3922fe2f0ed3b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('wav2clip_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
